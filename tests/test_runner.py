"""TTS ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ ëŸ¬ë„ˆ ëª¨ë“ˆ."""

import os
import time
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime
import yaml
import pandas as pd
import numpy as np
import librosa
from tqdm import tqdm

from utils.performance_monitor import PerformanceMonitor


class BenchmarkRunner:
    """TTS ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥ì„ ë²¤ì¹˜ë§ˆí¬í•˜ëŠ” í´ë˜ìŠ¤.
    
    ì—¬ëŸ¬ TTS ëª¨ë¸ì— ëŒ€í•´ ë™ì¼í•œ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤ì„ ì‹¤í–‰í•˜ê³ 
    ì¶”ë¡  ì†ë„, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë“±ì˜ ì„±ëŠ¥ ì§€í‘œë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.
    
    Attributes:
        config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        models_config: ëª¨ë¸ ì„¤ì • ì •ë³´
        models: ì´ˆê¸°í™”ëœ ëª¨ë¸ ë”•ì…”ë„ˆë¦¬
        test_sentences: í…ŒìŠ¤íŠ¸ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸
        results: ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        performance_monitor: ì„±ëŠ¥ ì¸¡ì • ëª¨ë‹ˆí„°
    """
    
    def __init__(self, config_path: str = 'config/models_config.yaml') -> None:
        """BenchmarkRunner ì´ˆê¸°í™”.
        
        Args:
            config_path: ëª¨ë¸ ì„¤ì • íŒŒì¼ ê²½ë¡œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€)
        
        Raises:
            FileNotFoundError: ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
        """
        self.project_root = Path(__file__).parent.parent
        self.config_path = self.project_root / config_path
        
        # ì„¤ì • íŒŒì¼ ë¡œë“œ
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                self.models_config = yaml.safe_load(f)
        except FileNotFoundError as e:
            raise FileNotFoundError(
                f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.config_path}"
            ) from e
        
        # ì´ˆê¸°í™”
        self.models: Dict[str, Any] = {}
        self.test_sentences: List[str] = []
        self.results: List[Dict[str, Any]] = []
        self.performance_monitor = PerformanceMonitor(device='auto')
        
        print(f"âœ“ BenchmarkRunner ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"  ì„¤ì • íŒŒì¼: {self.config_path}")
    
    def initialize_models(self) -> Dict[str, Any]:
        """ëª¨ë¸ë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        
        configì— ì •ì˜ëœ ëª¨ë“  ëª¨ë¸ì„ ë¡œë“œë¥¼ ì‹œë„í•©ë‹ˆë‹¤.
        ë¡œë“œ ì‹¤íŒ¨í•œ ëª¨ë¸ì€ ê±´ë„ˆë›°ê³  ë‹¤ë¥¸ ëª¨ë¸ì€ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.
        
        Returns:
            ì´ˆê¸°í™”ì— ì„±ê³µí•œ ëª¨ë¸ë“¤ì˜ ë”•ì…”ë„ˆë¦¬
            {model_name: model_instance}
        
        Raises:
            RuntimeError: ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ í•˜ë‚˜ë„ ì—†ëŠ” ê²½ìš°
        """
        print("\n" + "=" * 60)
        print("ëª¨ë¸ ì´ˆê¸°í™” ì‹œì‘")
        print("=" * 60)
        
        # configì— ì •ì˜ëœ ëª¨ë“  ëª¨ë¸ (ë²¤ì¹˜ë§ˆí¬ì— ì‚¬ìš©í•  ëª¨ë¸ë§Œ)
        available_models = ['gtts', 'melotts', 'cosyvoice', 'coqui']
        
        for model_name in available_models:
            if model_name not in self.models_config:
                print(f"\nâš ï¸  {model_name}: ì„¤ì • ì—†ìŒ, ê±´ë„ˆëœ€")
                continue
            
            try:
                print(f"\n[{model_name.upper()}] ì´ˆê¸°í™” ì¤‘...")
                
                if model_name == 'gtts':
                    from models.gtts_wrapper import GTTSWrapper
                    model = GTTSWrapper()
                    model.load_model()
                    self.models[model_name] = model
                    print(f"âœ“ {model_name} ì´ˆê¸°í™” ì„±ê³µ")
                
                elif model_name == 'zonos':
                    try:
                        from models.zonos import ZonosTTS
                        model = ZonosTTS(device='auto')
                        model.load_model()
                        self.models[model_name] = model
                        print(f"âœ“ {model_name} ì´ˆê¸°í™” ì„±ê³µ")
                    except (NotImplementedError, ImportError) as e:
                        print(f"âš ï¸  {model_name}: {str(e)[:100]}...")
                        print(f"  â†’ ì´ ëª¨ë¸ì€ ê±´ë„ˆëœë‹ˆë‹¤.")
                        continue
                
                elif model_name == 'cosyvoice':
                    try:
                        from models.cosyvoice import CosyVoiceTTS
                        model = CosyVoiceTTS(device='auto')
                        model.load_model()
                        self.models[model_name] = model
                        print(f"âœ“ {model_name} ì´ˆê¸°í™” ì„±ê³µ")
                    except (NotImplementedError, ImportError) as e:
                        print(f"âš ï¸  {model_name}: {str(e)[:100]}...")
                        print(f"  â†’ ì´ ëª¨ë¸ì€ ê±´ë„ˆëœë‹ˆë‹¤.")
                        continue
                
                elif model_name == 'kokoro':
                    try:
                        from models.kokoro import KokoroTTS
                        model = KokoroTTS(device='auto')
                        model.load_model()
                        self.models[model_name] = model
                        print(f"âœ“ {model_name} ì´ˆê¸°í™” ì„±ê³µ")
                    except (NotImplementedError, ImportError) as e:
                        print(f"âš ï¸  {model_name}: {str(e)[:100]}...")
                        print(f"  â†’ ì´ ëª¨ë¸ì€ ê±´ë„ˆëœë‹ˆë‹¤.")
                        continue
                
                elif model_name == 'melotts':
                    try:
                        from models.melotts import MeloTTSKorean
                        model = MeloTTSKorean(device='auto')
                        model.load_model()
                        self.models[model_name] = model
                        print(f"âœ“ {model_name} ì´ˆê¸°í™” ì„±ê³µ")
                    except (NotImplementedError, ImportError) as e:
                        print(f"âš ï¸  {model_name}: {str(e)[:100]}...")
                        print(f"  â†’ ì´ ëª¨ë¸ì€ ê±´ë„ˆëœë‹ˆë‹¤.")
                        continue
                
                elif model_name == 'coqui':
                    try:
                        from models.coqui_tts import CoquiTTS
                        model = CoquiTTS(device='auto')
                        model.load_model()
                        self.models[model_name] = model
                        print(f"âœ“ {model_name} ì´ˆê¸°í™” ì„±ê³µ")
                    except (NotImplementedError, ImportError) as e:
                        print(f"âš ï¸  {model_name}: {str(e)[:100]}...")
                        print(f"  â†’ ì´ ëª¨ë¸ì€ ê±´ë„ˆëœë‹ˆë‹¤.")
                        continue
                
            except Exception as e:
                print(f"âœ— {model_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                print(f"  â†’ ì´ ëª¨ë¸ì€ ê±´ë„ˆëœë‹ˆë‹¤.")
                continue
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
        if not self.models:
            raise RuntimeError(
                "ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. "
                "ìµœì†Œ í•œ ê°œ ì´ìƒì˜ ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
            )
        
        print("\n" + "=" * 60)
        print(f"âœ“ ì´ {len(self.models)}ê°œ ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"  í™œì„± ëª¨ë¸: {', '.join(self.models.keys())}")
        print("=" * 60)
        
        return self.models
    
    def load_test_sentences(self) -> List[str]:
        """í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤ì„ ë¡œë“œí•©ë‹ˆë‹¤.
        
        Returns:
            í…ŒìŠ¤íŠ¸ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸
        
        Raises:
            FileNotFoundError: í…ŒìŠ¤íŠ¸ ë¬¸ì¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
        """
        sentences_path = self.project_root / "tests" / "test_sentences.txt"
        
        try:
            with open(sentences_path, 'r', encoding='utf-8') as f:
                sentences = [
                    line.strip() 
                    for line in f 
                    if line.strip() and not line.startswith('#')
                ]
            
            self.test_sentences = sentences
            print(f"\nâœ“ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ ë¡œë“œ ì™„ë£Œ: {len(sentences)}ê°œ")
            
            return sentences
            
        except FileNotFoundError as e:
            raise FileNotFoundError(
                f"í…ŒìŠ¤íŠ¸ ë¬¸ì¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {sentences_path}"
            ) from e
    
    def run_single_test(
        self,
        model_name: str,
        text: str,
        iteration: int
    ) -> Dict[str, Any]:
        """ë‹¨ì¼ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        ì§€ì •ëœ ëª¨ë¸ë¡œ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ í•©ì„±í•˜ê³ 
        ì„±ëŠ¥ ì§€í‘œë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.
        
        Args:
            model_name: ëª¨ë¸ ì´ë¦„
            text: í•©ì„±í•  í…ìŠ¤íŠ¸
            iteration: ë°˜ë³µ íšŸìˆ˜ (íŒŒì¼ëª…ì— ì‚¬ìš©)
        
        Returns:
            í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
                - model: ëª¨ë¸ ì´ë¦„
                - text: ì…ë ¥ í…ìŠ¤íŠ¸
                - iteration: ë°˜ë³µ ë²ˆí˜¸
                - inference_time: ì¶”ë¡  ì‹œê°„ (ì´ˆ)
                - rtf: Real-Time Factor
                - peak_memory_mb: ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)
                - cpu_percent: CPU ì‚¬ìš©ë¥  (%)
                - gpu_memory_mb: GPU ë©”ëª¨ë¦¬ (MB, ì‚¬ìš© ì‹œ)
                - audio_duration: ì˜¤ë””ì˜¤ ê¸¸ì´ (ì´ˆ)
                - sample_rate: ìƒ˜í”Œë§ ë ˆì´íŠ¸
                - output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        
        Raises:
            ValueError: ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš°
            RuntimeError: í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨
        """
        if model_name not in self.models:
            raise ValueError(
                f"ëª¨ë¸ '{model_name}'ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                f"ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {list(self.models.keys())}"
            )
        
        model = self.models[model_name]
        
        try:
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            output_dir = self.project_root / "data" / "output" / model_name
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # ì„±ëŠ¥ ì¸¡ì •í•˜ë©° ìŒì„± í•©ì„±
            with self.performance_monitor.measure() as metrics:
                audio = model.synthesize(text)
            
            # ì˜¤ë””ì˜¤ ì €ì¥
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"iter_{iteration}_{timestamp}.wav"
            output_path = output_dir / output_filename
            
            model.save_audio(
                audio,
                str(output_path),
                sample_rate=model.sample_rate
            )
            
            # librosaë¡œ ì˜¤ë””ì˜¤ ê¸¸ì´ ì¸¡ì • (ê²€ì¦ìš©)
            try:
                y, sr = librosa.load(str(output_path), sr=None)
                audio_duration = librosa.get_duration(y=y, sr=sr)
            except Exception as e:
                # librosa ì‹¤íŒ¨ ì‹œ numpyë¡œ ê³„ì‚°
                print(f"  ê²½ê³ : librosa ì¸¡ì • ì‹¤íŒ¨, numpyë¡œ ê³„ì‚°: {e}")
                audio_duration = len(audio) / model.sample_rate
            
            # RTF ê³„ì‚°
            rtf = PerformanceMonitor.calculate_rtf(
                metrics['inference_time'],
                audio_duration
            )
            
            # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ìƒì„±
            result = {
                'model': model_name,
                'text': text,
                'text_length': len(text),
                'iteration': iteration,
                'inference_time': metrics['inference_time'],
                'rtf': rtf,
                'peak_memory_mb': metrics['peak_memory_mb'],
                'cpu_percent': metrics['cpu_percent'],
                'memory_percent': metrics.get('memory_percent', 0.0),
                'audio_duration': round(audio_duration, 3),
                'sample_rate': model.sample_rate,
                'output_path': str(output_path),
                'timestamp': timestamp,
            }
            
            # GPU ë©”íŠ¸ë¦­ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
            if 'gpu_memory_mb' in metrics:
                result['gpu_memory_mb'] = metrics['gpu_memory_mb']
            if 'gpu_max_memory_mb' in metrics:
                result['gpu_max_memory_mb'] = metrics['gpu_max_memory_mb']
            if 'gpu_utilization' in metrics:
                result['gpu_utilization'] = metrics['gpu_utilization']
            
            return result
            
        except Exception as e:
            raise RuntimeError(
                f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨ (model={model_name}, text='{text[:30]}...'): {e}"
            ) from e
    
    def run_benchmark(self, num_iterations: int = 5) -> None:
        """ì „ì²´ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        ëª¨ë“  ëª¨ë¸ì— ëŒ€í•´ ëª¨ë“  í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì„ ì§€ì •ëœ íšŸìˆ˜ë§Œí¼ ë°˜ë³µ ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        Args:
            num_iterations: ê° í…ŒìŠ¤íŠ¸ì˜ ë°˜ë³µ íšŸìˆ˜ (ê¸°ë³¸ê°’: 5)
        
        Raises:
            RuntimeError: ëª¨ë¸ì´ë‚˜ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì´ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš°
        """
        if not self.models:
            raise RuntimeError(
                "ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                "initialize_models()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”."
            )
        
        if not self.test_sentences:
            raise RuntimeError(
                "í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                "load_test_sentences()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”."
            )
        
        print("\n" + "=" * 60)
        print("ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì‹œì‘")
        print("=" * 60)
        print(f"  ëª¨ë¸ ìˆ˜: {len(self.models)}")
        print(f"  í…ŒìŠ¤íŠ¸ ë¬¸ì¥: {len(self.test_sentences)}ê°œ")
        print(f"  ë°˜ë³µ íšŸìˆ˜: {num_iterations}")
        print(f"  ì´ í…ŒìŠ¤íŠ¸: {len(self.models) * len(self.test_sentences) * num_iterations}ê°œ")
        print("=" * 60)
        
        # ì „ì²´ ì§„í–‰ ìƒí™© ì¶”ì 
        total_tests = len(self.models) * len(self.test_sentences) * num_iterations
        
        with tqdm(total=total_tests, desc="ë²¤ì¹˜ë§ˆí¬ ì§„í–‰") as pbar:
            for model_name in self.models.keys():
                print(f"\n\n[ëª¨ë¸: {model_name.upper()}]")
                
                for sentence_idx, text in enumerate(self.test_sentences, 1):
                    print(f"\n  ë¬¸ì¥ {sentence_idx}/{len(self.test_sentences)}: \"{text[:40]}{'...' if len(text) > 40 else ''}\"")
                    
                    for iteration in range(1, num_iterations + 1):
                        try:
                            # ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
                            result = self.run_single_test(
                                model_name=model_name,
                                text=text,
                                iteration=iteration
                            )
                            
                            # ê²°ê³¼ ì €ì¥
                            self.results.append(result)
                            
                            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                            pbar.set_postfix({
                                'model': model_name,
                                'rtf': f"{result['rtf']:.3f}",
                                'time': f"{result['inference_time']:.2f}s"
                            })
                            pbar.update(1)
                            
                        except Exception as e:
                            print(f"\n    âœ— í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ (ë°˜ë³µ {iteration}): {e}")
                            pbar.update(1)
                            continue
                        
                        # ëª¨ë¸ ê°„ ê°„ê²© (API ì œí•œ ê³ ë ¤)
                        time.sleep(0.5)
        
        print("\n" + "=" * 60)
        print(f"âœ“ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
        print(f"  ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {len(self.results)}ê°œ")
        print("=" * 60)
    
    def save_results(self) -> None:
        """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
        
        ê²°ê³¼ë¥¼ CSV íŒŒì¼ê³¼ í†µê³„ ìš”ì•½ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        
        Raises:
            RuntimeError: ì €ì¥í•  ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
        """
        if not self.results:
            raise RuntimeError(
                "ì €ì¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. run_benchmark()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”."
            )
        
        print("\n" + "=" * 60)
        print("ê²°ê³¼ ì €ì¥ ì¤‘...")
        print("=" * 60)
        
        # DataFrame ìƒì„±
        df = pd.DataFrame(self.results)
        
        # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
        metrics_dir = self.project_root / "results" / "metrics"
        metrics_dir.mkdir(parents=True, exist_ok=True)
        
        # 1. ì „ì²´ ê²°ê³¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_path = metrics_dir / f"benchmark_results_{timestamp}.csv"
        df.to_csv(results_path, index=False, encoding='utf-8-sig')
        print(f"\nâœ“ ì „ì²´ ê²°ê³¼ ì €ì¥: {results_path}")
        
        # 2. í†µê³„ ìš”ì•½ ìƒì„±
        print("\ní†µê³„ ìš”ì•½ ìƒì„± ì¤‘...")
        
        # ëª¨ë¸ë³„ í†µê³„
        summary_data = []
        
        for model_name in df['model'].unique():
            model_df = df[df['model'] == model_name]
            
            summary = {
                'model': model_name,
                'test_count': len(model_df),
                
                # ì¶”ë¡  ì‹œê°„
                'inference_time_mean': model_df['inference_time'].mean(),
                'inference_time_std': model_df['inference_time'].std(),
                'inference_time_min': model_df['inference_time'].min(),
                'inference_time_max': model_df['inference_time'].max(),
                
                # RTF
                'rtf_mean': model_df['rtf'].mean(),
                'rtf_std': model_df['rtf'].std(),
                'rtf_min': model_df['rtf'].min(),
                'rtf_max': model_df['rtf'].max(),
                
                # ë©”ëª¨ë¦¬
                'peak_memory_mean': model_df['peak_memory_mb'].mean(),
                'peak_memory_std': model_df['peak_memory_mb'].std(),
                'peak_memory_max': model_df['peak_memory_mb'].max(),
                
                # CPU
                'cpu_percent_mean': model_df['cpu_percent'].mean(),
                'cpu_percent_std': model_df['cpu_percent'].std(),
                
                # ì˜¤ë””ì˜¤
                'audio_duration_mean': model_df['audio_duration'].mean(),
                'sample_rate': model_df['sample_rate'].iloc[0],
            }
            
            # GPU ë©”íŠ¸ë¦­ (ìˆëŠ” ê²½ìš°)
            if 'gpu_memory_mb' in model_df.columns:
                gpu_data = model_df['gpu_memory_mb'].dropna()
                if len(gpu_data) > 0:
                    summary['gpu_memory_mean'] = gpu_data.mean()
                    summary['gpu_memory_max'] = gpu_data.max()
            
            summary_data.append(summary)
        
        summary_df = pd.DataFrame(summary_data)
        summary_path = metrics_dir / f"summary_statistics_{timestamp}.csv"
        summary_df.to_csv(summary_path, index=False, encoding='utf-8-sig')
        print(f"âœ“ í†µê³„ ìš”ì•½ ì €ì¥: {summary_path}")
        
        # 3. ì½˜ì†”ì— ìš”ì•½ ì¶œë ¥
        print("\n" + "=" * 60)
        print("ë²¤ì¹˜ë§ˆí¬ ìš”ì•½")
        print("=" * 60)
        
        for _, row in summary_df.iterrows():
            print(f"\n[{row['model'].upper()}]")
            print(f"  í…ŒìŠ¤íŠ¸ ìˆ˜: {row['test_count']}")
            print(f"  í‰ê·  ì¶”ë¡  ì‹œê°„: {row['inference_time_mean']:.3f}s (Â±{row['inference_time_std']:.3f})")
            print(f"  í‰ê·  RTF: {row['rtf_mean']:.4f} (Â±{row['rtf_std']:.4f})")
            print(f"  ìµœëŒ€ ë©”ëª¨ë¦¬: {row['peak_memory_max']:.2f} MB")
            
            if row['rtf_mean'] < 0.5:
                print(f"  í‰ê°€: ğŸ‰ ë§¤ìš° ë¹ ë¦„ (ëª©í‘œ ë‹¬ì„±!)")
            elif row['rtf_mean'] < 1.0:
                print(f"  í‰ê°€: âœ… ë¹ ë¦„ (ì‹¤ì‹œê°„ë³´ë‹¤ ë¹ ë¦„)")
            else:
                print(f"  í‰ê°€: âš ï¸  ëŠë¦¼ (ì‹¤ì‹œê°„ë³´ë‹¤ ëŠë¦¼)")
        
        print("\n" + "=" * 60)
        print("âœ… ëª¨ë“  ê²°ê³¼ ì €ì¥ ì™„ë£Œ!")
        print("=" * 60)

